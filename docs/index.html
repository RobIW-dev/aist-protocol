<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AIST Protocol — Context Cost Calculator</title>
<meta name="description" content="See exactly how much an AIST handoff costs on your model. Interactive calculator covering 40+ LLMs from local 7B to 10M-token enterprise.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
  *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

  :root {
    --bg: #09090b;
    --bg-raised: #0f1117;
    --bg-hover: #161821;
    --border: #1e2030;
    --border-light: #2a2d42;
    --text: #f1f5f9;
    --text-dim: #b8c4d6;
    --text-muted: #94a3bb;
    --accent-red: #ef4444;
    --accent-orange: #f97316;
    --accent-yellow: #eab308;
    --accent-green: #22c55e;
    --accent-blue: #3b82f6;
    --accent-purple: #8b5cf6;
    --accent-cyan: #06b6d4;
    --accent-pink: #ec4899;
    --mono: 'JetBrains Mono', 'SF Mono', 'Fira Code', monospace;
    --sans: 'Inter', -apple-system, sans-serif;
  }

  body {
    font-family: var(--mono);
    background: var(--bg);
    color: var(--text);
    line-height: 1.6;
    -webkit-font-smoothing: antialiased;
  }

  .container {
    max-width: 1100px;
    margin: 0 auto;
    padding: 32px 24px 64px;
  }

  /* Header */
  .header { margin-bottom: 36px; }
  .header-tag {
    font-size: 11px;
    letter-spacing: 3px;
    color: var(--text-muted);
    text-transform: uppercase;
    margin-bottom: 8px;
  }
  .header h1 {
    font-family: var(--sans);
    font-size: 32px;
    font-weight: 700;
    color: #f8fafc;
    line-height: 1.2;
    margin-bottom: 10px;
  }
  .header p {
    font-size: 14px;
    color: var(--text-dim);
    line-height: 1.6;
    max-width: 680px;
  }
  .header .highlight { color: var(--accent-red); font-weight: 600; }
  .header .universal {
    display: inline-block;
    margin-top: 10px;
    padding: 6px 14px;
    font-size: 11px;
    letter-spacing: 0.5px;
    color: var(--accent-cyan);
    border: 1px solid rgba(6, 182, 212, 0.3);
    border-radius: 4px;
    background: rgba(6, 182, 212, 0.06);
    line-height: 1.5;
  }

  /* Controls */
  .controls {
    display: flex;
    gap: 28px;
    margin-bottom: 24px;
    flex-wrap: wrap;
  }
  .control-group label {
    display: block;
    font-size: 10px;
    letter-spacing: 2px;
    color: var(--text-muted);
    text-transform: uppercase;
    margin-bottom: 8px;
  }
  .btn-row { display: flex; gap: 4px; flex-wrap: wrap; }
  .btn {
    padding: 8px 14px;
    font-size: 12px;
    font-family: var(--mono);
    background: transparent;
    color: var(--text-muted);
    border: 1px solid var(--border);
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.15s;
    white-space: nowrap;
  }
  .btn:hover { border-color: var(--border-light); color: var(--text-dim); }
  .btn.active {
    background: var(--bg-raised);
    color: #f8fafc;
    border-color: var(--border-light);
  }

  /* Token display */
  .token-display {
    display: flex;
    align-items: baseline;
    gap: 14px;
    margin-bottom: 24px;
    padding: 18px 22px;
    background: var(--bg-raised);
    border-radius: 6px;
    border: 1px solid var(--border);
  }
  .token-display .num {
    font-size: 40px;
    font-weight: 700;
    color: #f8fafc;
  }
  .token-display .meta {
    font-size: 13px;
    color: var(--text-muted);
  }

  /* Filter / Category Toggle */
  .filter-bar {
    display: flex;
    gap: 6px;
    margin-bottom: 20px;
    flex-wrap: wrap;
  }
  .filter-btn {
    padding: 5px 12px;
    font-size: 10px;
    font-family: var(--mono);
    letter-spacing: 1px;
    text-transform: uppercase;
    background: transparent;
    color: var(--text-muted);
    border: 1px solid var(--border);
    border-radius: 3px;
    cursor: pointer;
    transition: all 0.15s;
  }
  .filter-btn:hover { border-color: var(--border-light); }
  .filter-btn.active {
    background: var(--bg-raised);
    color: var(--text);
    border-color: var(--border-light);
  }

  /* Category sections */
  .category { margin-bottom: 22px; }
  .category-header {
    font-size: 10px;
    letter-spacing: 2px;
    color: var(--text-muted);
    text-transform: uppercase;
    padding-bottom: 6px;
    border-bottom: 1px solid var(--border);
    margin-bottom: 4px;
  }

  /* Model rows */
  .model-row {
    display: grid;
    grid-template-columns: 240px 70px 1fr 70px 90px;
    align-items: center;
    gap: 10px;
    padding: 7px 0;
    border-bottom: 1px solid #1a1d2e;
    transition: background 0.1s;
  }
  .model-row:hover { background: var(--bg-hover); }
  .model-name { font-size: 12px; color: #e2e8f0; }
  .model-name .access {
    font-size: 10px;
    color: var(--text-muted);
    margin-left: 6px;
  }
  .model-ctx { font-size: 11px; color: var(--text-dim); text-align: right; }
  .bar-container {
    height: 18px;
    background: #1a1d2e;
    border-radius: 2px;
    overflow: hidden;
    position: relative;
  }
  .bar-fill {
    height: 100%;
    border-radius: 2px;
    opacity: 0.9;
    transition: width 0.3s ease;
    min-width: 2px;
  }
  .model-pct { font-size: 13px; font-weight: 600; text-align: right; }
  .model-impact {
    font-size: 9px;
    letter-spacing: 1.5px;
    text-align: right;
    text-transform: uppercase;
  }

  /* Insight box */
  .insight {
    margin-top: 32px;
    padding: 22px;
    background: var(--bg-raised);
    border-radius: 6px;
    border: 1px solid var(--border);
  }
  .insight-label {
    font-size: 10px;
    letter-spacing: 2px;
    color: var(--text-muted);
    text-transform: uppercase;
    margin-bottom: 10px;
  }
  .insight-body {
    font-size: 13px;
    color: var(--text-dim);
    line-height: 1.8;
  }
  .insight-body .white { color: #f8fafc; }
  .insight-body .red { color: var(--accent-red); font-weight: 600; }
  .insight-body .orange { color: var(--accent-orange); font-weight: 600; }
  .insight-body .green { color: var(--accent-green); font-weight: 600; }

  /* Quick comparison */
  .quick-compare-header {
    display: flex;
    align-items: center;
    gap: 10px;
    margin-top: 24px;
    margin-bottom: 10px;
  }
  .shuffle-btn {
    font-family: var(--mono);
    font-size: 11px;
    padding: 4px 10px;
    background: transparent;
    color: var(--text-muted);
    border: 1px solid var(--border);
    border-radius: 4px;
    cursor: pointer;
    transition: all 0.15s;
  }
  .shuffle-btn:hover { border-color: var(--border-light); color: var(--text-dim); }
  .quick-compare {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 12px;
  }
  .compare-card {
    padding: 16px;
    background: var(--bg-raised);
    border-radius: 6px;
    border: 1px solid var(--border);
    text-align: center;
    display: flex;
    flex-direction: column;
    height: 120px;
  }
  .compare-card .label-row {
    height: 28px;
    display: flex;
    align-items: center;
    justify-content: center;
    flex-shrink: 0;
  }
  .compare-card .model-pick {
    font-family: var(--mono);
    font-size: 10px;
    letter-spacing: 1px;
    text-transform: uppercase;
    background: transparent;
    color: var(--text-muted);
    border: 1px solid transparent;
    border-radius: 3px;
    padding: 3px 8px;
    cursor: pointer;
    transition: all 0.15s;
    max-width: 100%;
    text-overflow: ellipsis;
    overflow: hidden;
    white-space: nowrap;
    -webkit-appearance: none;
    appearance: none;
  }
  .compare-card .model-pick:hover,
  .compare-card .model-pick:focus {
    border-color: var(--border-light);
    color: var(--text-dim);
    outline: none;
  }
  .compare-card .value {
    font-size: 28px;
    font-weight: 700;
    flex: 1;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  .compare-card .sub {
    font-size: 11px;
    color: var(--text-muted);
    flex-shrink: 0;
    height: 18px;
  }

  /* Footer */
  .footer {
    margin-top: 32px;
    font-size: 11px;
    color: var(--text-muted);
    line-height: 1.7;
  }

  /* Language selector */
  .lang-bar {
    display: flex;
    align-items: center;
    gap: 8px;
    margin-bottom: 20px;
    flex-wrap: wrap;
  }
  .lang-bar label {
    font-size: 10px;
    letter-spacing: 1px;
    color: var(--text-muted);
    text-transform: uppercase;
  }
  .lang-select {
    font-family: var(--mono);
    font-size: 12px;
    padding: 6px 10px;
    background: var(--bg-raised);
    color: var(--text);
    border: 1px solid var(--border);
    border-radius: 4px;
    cursor: pointer;
    outline: none;
  }
  .lang-select:hover { border-color: var(--border-light); }
  .lang-pop {
    font-size: 10px;
    color: var(--text-muted);
    margin-left: 4px;
  }

  /* RTL support */
  [dir="rtl"] .model-row { direction: rtl; }
  [dir="rtl"] .model-ctx { text-align: left; }
  [dir="rtl"] .model-pct { text-align: left; }
  [dir="rtl"] .model-impact { text-align: left; }

  /* License modal */
  .license-link {
    cursor: pointer;
    text-decoration: underline;
    text-decoration-style: dotted;
    text-underline-offset: 3px;
  }
  .license-link:hover { color: var(--text); }
  .modal-overlay {
    display: none;
    position: fixed;
    inset: 0;
    background: rgba(0,0,0,0.7);
    z-index: 1000;
    align-items: center;
    justify-content: center;
    padding: 24px;
    backdrop-filter: blur(4px);
  }
  .modal-overlay.open { display: flex; }
  .modal {
    background: var(--bg-raised);
    border: 1px solid var(--border-light);
    border-radius: 10px;
    max-width: 560px;
    width: 100%;
    padding: 28px 30px;
    position: relative;
    max-height: 85vh;
    overflow-y: auto;
  }
  .modal-close {
    position: absolute;
    top: 14px;
    right: 16px;
    font-size: 20px;
    background: none;
    border: none;
    color: var(--text-muted);
    cursor: pointer;
    padding: 4px 8px;
    line-height: 1;
    font-family: var(--mono);
  }
  .modal-close:hover { color: var(--text); }
  .modal h2 {
    font-family: var(--sans);
    font-size: 18px;
    color: #f8fafc;
    margin-bottom: 16px;
  }
  .modal p {
    font-size: 13px;
    color: var(--text-dim);
    line-height: 1.8;
    margin-bottom: 12px;
  }
  .modal .license-item {
    display: flex;
    gap: 10px;
    margin-bottom: 10px;
    font-size: 13px;
    color: var(--text-dim);
    line-height: 1.6;
  }
  .modal .license-icon {
    font-size: 18px;
    flex-shrink: 0;
    width: 24px;
    text-align: center;
  }
  .modal .license-full {
    margin-top: 16px;
    padding-top: 14px;
    border-top: 1px solid var(--border);
    font-size: 11px;
    color: var(--text-muted);
  }
  .modal .license-full a { color: var(--accent-blue); }
  .footer a { color: var(--accent-blue); text-decoration: none; }
  .footer a:hover { text-decoration: underline; }

  /* Responsive */
  @media (max-width: 768px) {
    .model-row {
      grid-template-columns: 1fr 50px 80px;
      gap: 6px;
    }
    .bar-container, .model-impact { display: none; }
    .header h1 { font-size: 24px; }
    .token-display .num { font-size: 30px; }
  }
</style>
</head>
<body>
<div class="container" id="app"></div>

<!-- License modal -->
<div class="modal-overlay" id="licenseModal" onclick="if(event.target===this)closeLicense()">
  <div class="modal">
    <button class="modal-close" onclick="closeLicense()">&times;</button>
    <h2>CC BY-SA 4.0</h2>
    <p>The AIST Protocol is released under the <strong>Creative Commons Attribution-ShareAlike 4.0 International</strong> license. In plain language:</p>
    <div class="license-item"><span class="license-icon">&#10003;</span><span><strong>Use it freely</strong> &mdash; for personal, commercial, academic, or any other purpose. No permission needed.</span></div>
    <div class="license-item"><span class="license-icon">&#10003;</span><span><strong>Modify and adapt</strong> &mdash; build tools, create variants, extend the protocol, translate it. Make it yours.</span></div>
    <div class="license-item"><span class="license-icon">&#10003;</span><span><strong>Share and redistribute</strong> &mdash; copy it, host it, include it in your projects or products.</span></div>
    <div class="license-item"><span class="license-icon">&#9998;</span><span><strong>Give credit</strong> &mdash; mention the AIST Protocol and link back to the source.</span></div>
    <div class="license-item"><span class="license-icon">&#9998;</span><span><strong>Share alike</strong> &mdash; if you modify and redistribute, use the same or a compatible license.</span></div>
    <div class="license-full">
      Full legal text: <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode" target="_blank">creativecommons.org/licenses/by-sa/4.0</a>
    </div>
  </div>
</div>

<script>
// =====================================================
// INTERNATIONALIZATION — 22 languages
// Protocol terms (FULL, COMPACT, TERSE, MAX, etc.) stay
// English as they're spec terminology.
// =====================================================
const T = {
  en: {
    lang: "English",
    tag: "AIST Protocol v0.5 · Open Source · CC BY-SA 4.0",
    title: "Context Cost Calculator",
    subtitle: "How much of your context window does an AIST handoff actually cost?",
    highlight: "The less context you have, the more AIST matters.",
    universal: "Plain text. No vendor lock-in. One handoff works on ChatGPT, Claude, Gemini, Llama, and every other LLM.",
    anyModel: "Any LLM",
    notation: "Notation Density",
    fidelity: "Fidelity Level",
    tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Show Categories",
    all: "ALL",
    ofContext: "of context used",
    insightLabel: "The Takeaway",
    insight: (tokens, local, free, pro) =>
      `At <span class="white">${tokens} tokens</span>, a local 7B model with Ollama's 2K default pays <span class="red">${local}</span> of its entire context for full project continuity. A ChatGPT Free user pays <span class="orange">${free}</span>. Claude Pro pays <span class="green">${pro}</span>. Same protocol. Same state. Same continuity. Vastly different cost.`,
    insightPunch: "The people with the smallest context windows get the biggest benefit from AIST. Continuity shouldn't be a premium feature.",
    terseTip: (tokens, pct) => `At TERSE notation, even a 2K local model carries session state for just <span class="orange">${pct}</span> — project continuity on hardware that fits in your pocket.`,
    compactTip: "COMPACT notation halves the cost while keeping the state human-scannable. Every model below 32K sees meaningful savings.",
    fullTip: "Try switching to COMPACT or TERSE notation to see how much smaller the footprint gets — especially important for local and free-tier users.",
    models: "models",
    impact: { TRANSFORMATIVE: "TRANSFORMATIVE", CRITICAL: "CRITICAL", HIGH: "HIGH", SIGNIFICANT: "SIGNIFICANT", MODERATE: "MODERATE", LOW: "LOW", NEGLIGIBLE: "NEGLIGIBLE" },
    fidLabels: ["Everything preserved", "Drop energy/constraints", "Core decisions + threads", "Essence + handoff only"],
    notLabels: ["Human + Machine readable", "Abbreviated, scannable", "Telegraphic, machine-focused"],
    catLabels: {
      "edge": "On-Device / Edge", "local": "Local (Ollama / llama.cpp)", "free": "Free Tiers",
      "paid": "Paid Consumer ($20/mo)", "pro": "Pro / Business ($25-200/mo)", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Budget & Open Source", "self-hosted-max": "Self-Hosted (Max Advertised)"
    },
  },
  zh: {
    lang: "中文",
    tag: "AIST 协议 v0.5 · 开源 · CC BY-SA 4.0",
    title: "上下文成本计算器",
    subtitle: "一次 AIST 交接实际消耗您多少上下文窗口？",
    highlight: "上下文越小，AIST 的价值越大。",
    universal: "纯文本。无供应商锁定。一次交接适用于 ChatGPT、Claude、Gemini、Llama 及所有其他大语言模型。",
    anyModel: "任何模型",
    notation: "表示密度",
    fidelity: "保真度",
    tokens: "令牌",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "显示分类",
    all: "全部",
    ofContext: "上下文占比",
    insightLabel: "核心结论",
    insight: (tokens, local, free, pro) =>
      `在 <span class="white">${tokens} 个令牌</span>下，使用 Ollama 默认 2K 上下文的本地 7B 模型需要支付整个上下文的 <span class="red">${local}</span> 来获得完整的项目连续性。ChatGPT 免费用户支付 <span class="orange">${free}</span>。Claude Pro 支付 <span class="green">${pro}</span>。相同的协议，相同的状态，截然不同的成本。`,
    insightPunch: "上下文窗口最小的人从 AIST 中获益最多。连续性不应该是付费功能。",
    terseTip: (tokens, pct) => `在 TERSE 表示法下，即使 2K 本地模型也只需 <span class="orange">${pct}</span> 即可携带会话状态。`,
    compactTip: "COMPACT 表示法将成本减半，同时保持人类可读性。",
    fullTip: "尝试切换到 COMPACT 或 TERSE 表示法，看看占用空间如何缩小——对本地和免费用户尤其重要。",
    models: "个模型",
    impact: { TRANSFORMATIVE: "革命性", CRITICAL: "关键", HIGH: "高", SIGNIFICANT: "显著", MODERATE: "中等", LOW: "低", NEGLIGIBLE: "可忽略" },
    fidLabels: ["完整保留", "精简约束", "核心决策+线程", "仅摘要+交接"],
    notLabels: ["人机可读", "缩写·可扫读", "电报式·机器优先"],
    catLabels: {
      "edge": "设备端/边缘", "local": "本地 (Ollama / llama.cpp)", "free": "免费层",
      "paid": "付费用户 ($20/月)", "pro": "专业/商务 ($25-200/月)", "enterprise": "企业版",
      "api-premium": "API — 高端", "api-budget": "API — 经济/开源", "self-hosted-max": "自托管（最大）"
    },
  },
  es: {
    lang: "Español",
    tag: "Protocolo AIST v0.5 · Código Abierto · CC BY-SA 4.0",
    title: "Calculadora de Costo de Contexto",
    subtitle: "¿Cuánto de tu ventana de contexto consume un handoff AIST?",
    highlight: "Cuanto menos contexto tengas, más importa AIST.",
    universal: "Texto plano. Sin dependencia de proveedor. Un handoff funciona en ChatGPT, Claude, Gemini, Llama y cualquier otro LLM.",
    anyModel: "Cualquier LLM",
    notation: "Densidad de Notación",
    fidelity: "Nivel de Fidelidad",
    tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Mostrar Categorías",
    all: "TODAS",
    ofContext: "del contexto usado",
    insightLabel: "La Conclusión",
    insight: (tokens, local, free, pro) =>
      `Con <span class="white">${tokens} tokens</span>, un modelo local 7B con Ollama (2K por defecto) paga <span class="red">${local}</span> de todo su contexto para continuidad del proyecto. Un usuario gratuito de ChatGPT paga <span class="orange">${free}</span>. Claude Pro paga <span class="green">${pro}</span>. Mismo protocolo. Mismo estado. Costo muy diferente.`,
    insightPunch: "Las personas con las ventanas de contexto más pequeñas obtienen el mayor beneficio de AIST. La continuidad no debería ser una función premium.",
    terseTip: (tokens, pct) => `Con notación TERSE, incluso un modelo local de 2K mantiene el estado de sesión por solo <span class="orange">${pct}</span>.`,
    compactTip: "La notación COMPACT reduce el costo a la mitad manteniendo la legibilidad humana.",
    fullTip: "Prueba cambiar a COMPACT o TERSE para ver cuánto se reduce la huella — especialmente importante para usuarios locales y gratuitos.",
    models: "modelos",
    impact: { TRANSFORMATIVE: "TRANSFORMADOR", CRITICAL: "CRÍTICO", HIGH: "ALTO", SIGNIFICANT: "SIGNIFICATIVO", MODERATE: "MODERADO", LOW: "BAJO", NEGLIGIBLE: "INSIGNIFICANTE" },
    fidLabels: ["Todo preservado", "Sin energía/restricciones", "Decisiones + hilos", "Solo esencia + handoff"],
    notLabels: ["Humano + Máquina", "Abreviado, escaneable", "Telegráfico, para máquinas"],
    catLabels: {
      "edge": "Dispositivo / Edge", "local": "Local (Ollama / llama.cpp)", "free": "Nivel Gratuito",
      "paid": "Consumidor ($20/mes)", "pro": "Pro / Negocios ($25-200/mes)", "enterprise": "Empresarial",
      "api-premium": "API — Premium", "api-budget": "API — Económica", "self-hosted-max": "Auto-hospedado (Máximo)"
    },
  },
  hi: {
    lang: "हिन्दी",
    tag: "AIST प्रोटोकॉल v0.5 · ओपन सोर्स · CC BY-SA 4.0",
    title: "कॉन्टेक्स्ट कॉस्ट कैलकुलेटर",
    subtitle: "AIST हैंडऑफ़ आपकी कॉन्टेक्स्ट विंडो का कितना हिस्सा लेता है?",
    highlight: "जितना कम कॉन्टेक्स्ट, उतना ज़्यादा AIST मायने रखता है।",
    universal: "सादा टेक्स्ट। कोई वेंडर लॉक-इन नहीं। एक हैंडऑफ़ ChatGPT, Claude, Gemini, Llama और हर अन्य LLM पर काम करता है।",
    anyModel: "कोई भी LLM",
    notation: "नोटेशन घनत्व",
    fidelity: "फ़िडेलिटी स्तर",
    tokens: "टोकन",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "श्रेणियाँ दिखाएँ",
    all: "सभी",
    ofContext: "कॉन्टेक्स्ट का उपयोग",
    insightLabel: "मुख्य निष्कर्ष",
    insight: (tokens, local, free, pro) =>
      `<span class="white">${tokens} टोकन</span> पर, Ollama के 2K डिफ़ॉल्ट वाला लोकल 7B मॉडल अपने पूरे कॉन्टेक्स्ट का <span class="red">${local}</span> भुगतान करता है। ChatGPT मुफ़्त उपयोगकर्ता <span class="orange">${free}</span> देता है। Claude Pro <span class="green">${pro}</span> देता है। वही प्रोटोकॉल। बहुत अलग लागत।`,
    insightPunch: "सबसे छोटी कॉन्टेक्स्ट विंडो वालों को AIST से सबसे ज़्यादा फ़ायदा होता है। निरंतरता प्रीमियम फ़ीचर नहीं होनी चाहिए।",
    terseTip: (tokens, pct) => `TERSE नोटेशन में, 2K लोकल मॉडल भी सिर्फ़ <span class="orange">${pct}</span> में सेशन स्टेट रखता है।`,
    compactTip: "COMPACT नोटेशन लागत को आधा करता है और मानव-पठनीय रहता है।",
    fullTip: "COMPACT या TERSE पर स्विच करके देखें कि फ़ुटप्रिंट कितना कम होता है।",
    models: "मॉडल",
    impact: { TRANSFORMATIVE: "परिवर्तनकारी", CRITICAL: "गंभीर", HIGH: "उच्च", SIGNIFICANT: "महत्वपूर्ण", MODERATE: "मध्यम", LOW: "कम", NEGLIGIBLE: "नगण्य" },
    fidLabels: ["सब कुछ संरक्षित", "ऊर्जा/बाधाएँ हटाएँ", "मूल निर्णय + थ्रेड", "केवल सार + हैंडऑफ़"],
    notLabels: ["मानव + मशीन पठनीय", "संक्षिप्त, स्कैन योग्य", "टेलीग्राफ़िक, मशीन-केंद्रित"],
    catLabels: {
      "edge": "डिवाइस / एज", "local": "लोकल (Ollama / llama.cpp)", "free": "मुफ़्त",
      "paid": "भुगतान ($20/माह)", "pro": "प्रो / बिज़नेस", "enterprise": "एंटरप्राइज़",
      "api-premium": "API — प्रीमियम", "api-budget": "API — बजट", "self-hosted-max": "सेल्फ़-होस्टेड (अधिकतम)"
    },
  },
  ar: {
    lang: "العربية",
    dir: "rtl",
    tag: "بروتوكول AIST الإصدار 0.5 · مفتوح المصدر · CC BY-SA 4.0",
    title: "حاسبة تكلفة السياق",
    subtitle: "كم من نافذة السياق يستهلك تسليم AIST؟",
    highlight: "كلما قلّ سياقك، زادت أهمية AIST.",
    universal: "نص عادي. بدون تقييد بمزوّد. تسليم واحد يعمل على ChatGPT وClaude وGemini وLlama وأي نموذج لغوي آخر.",
    anyModel: "أي نموذج",
    notation: "كثافة الترميز",
    fidelity: "مستوى الدقة",
    tokens: "رمز",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "عرض الفئات",
    all: "الكل",
    ofContext: "من السياق المستخدم",
    insightLabel: "الخلاصة",
    insight: (tokens, local, free, pro) =>
      `عند <span class="white">${tokens} رمز</span>، نموذج 7B محلي مع Ollama (افتراضي 2K) يدفع <span class="red">${local}</span> من سياقه الكامل. مستخدم ChatGPT المجاني يدفع <span class="orange">${free}</span>. Claude Pro يدفع <span class="green">${pro}</span>. نفس البروتوكول. نفس الحالة. تكلفة مختلفة تمامًا.`,
    insightPunch: "الأشخاص الذين لديهم أصغر نوافذ سياق يحصلون على أكبر فائدة من AIST. الاستمرارية لا ينبغي أن تكون ميزة مدفوعة.",
    terseTip: (tokens, pct) => `مع ترميز TERSE، حتى نموذج 2K محلي يحمل حالة الجلسة بـ <span class="orange">${pct}</span> فقط.`,
    compactTip: "ترميز COMPACT يخفّض التكلفة للنصف مع الحفاظ على قابلية القراءة.",
    fullTip: "جرّب التبديل إلى COMPACT أو TERSE لترى مدى انخفاض الحجم.",
    models: "نماذج",
    impact: { TRANSFORMATIVE: "تحويلي", CRITICAL: "حرج", HIGH: "عالي", SIGNIFICANT: "مهم", MODERATE: "متوسط", LOW: "منخفض", NEGLIGIBLE: "ضئيل" },
    fidLabels: ["كل شيء محفوظ", "حذف الطاقة/القيود", "القرارات الأساسية", "الجوهر + التسليم فقط"],
    notLabels: ["قابل للقراءة البشرية والآلية", "مختصر، قابل للمسح", "برقي، للآلة"],
    catLabels: {
      "edge": "على الجهاز / الحافة", "local": "محلي (Ollama / llama.cpp)", "free": "الطبقة المجانية",
      "paid": "مستهلك مدفوع ($20/شهر)", "pro": "احترافي / أعمال", "enterprise": "مؤسسات",
      "api-premium": "API — متميز", "api-budget": "API — اقتصادي", "self-hosted-max": "مستضاف ذاتيًا (الحد الأقصى)"
    },
  },
  pt: {
    lang: "Português",
    tag: "Protocolo AIST v0.5 · Código Aberto · CC BY-SA 4.0",
    title: "Calculadora de Custo de Contexto",
    subtitle: "Quanto da sua janela de contexto um handoff AIST realmente custa?",
    highlight: "Quanto menos contexto você tem, mais o AIST importa.",
    universal: "Texto simples. Sem dependência de fornecedor. Um handoff funciona no ChatGPT, Claude, Gemini, Llama e qualquer outro LLM.",
    anyModel: "Qualquer LLM",
    notation: "Densidade de Notação",
    fidelity: "Nível de Fidelidade",
    tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Mostrar Categorias",
    all: "TODAS",
    ofContext: "do contexto usado",
    insightLabel: "A Conclusão",
    insight: (tokens, local, free, pro) =>
      `Com <span class="white">${tokens} tokens</span>, um modelo local 7B com Ollama (2K padrão) paga <span class="red">${local}</span> de todo seu contexto. Um usuário gratuito do ChatGPT paga <span class="orange">${free}</span>. Claude Pro paga <span class="green">${pro}</span>. Mesmo protocolo. Custo muito diferente.`,
    insightPunch: "As pessoas com as menores janelas de contexto obtêm o maior benefício do AIST. Continuidade não deveria ser um recurso premium.",
    terseTip: (tokens, pct) => `Com notação TERSE, até um modelo local de 2K mantém o estado da sessão por apenas <span class="orange">${pct}</span>.`,
    compactTip: "A notação COMPACT reduz o custo pela metade mantendo a legibilidade.",
    fullTip: "Tente mudar para COMPACT ou TERSE para ver quanto a pegada diminui.",
    models: "modelos",
    impact: { TRANSFORMATIVE: "TRANSFORMADOR", CRITICAL: "CRÍTICO", HIGH: "ALTO", SIGNIFICANT: "SIGNIFICATIVO", MODERATE: "MODERADO", LOW: "BAIXO", NEGLIGIBLE: "INSIGNIFICANTE" },
    fidLabels: ["Tudo preservado", "Sem energia/restrições", "Decisões + threads", "Apenas essência + handoff"],
    notLabels: ["Humano + Máquina", "Abreviado, escaneável", "Telegráfico, para máquinas"],
    catLabels: {
      "edge": "No Dispositivo / Edge", "local": "Local (Ollama / llama.cpp)", "free": "Nível Gratuito",
      "paid": "Consumidor ($20/mês)", "pro": "Pro / Negócios", "enterprise": "Empresarial",
      "api-premium": "API — Premium", "api-budget": "API — Econômica", "self-hosted-max": "Auto-hospedado (Máximo)"
    },
  },
  ru: {
    lang: "Русский",
    tag: "Протокол AIST v0.5 · Открытый исходный код · CC BY-SA 4.0",
    title: "Калькулятор стоимости контекста",
    subtitle: "Сколько контекстного окна занимает передача AIST?",
    highlight: "Чем меньше контекст, тем больше значит AIST.",
    universal: "Обычный текст. Без привязки к вендору. Одна передача работает в ChatGPT, Claude, Gemini, Llama и любой другой LLM.",
    anyModel: "Любая LLM",
    notation: "Плотность нотации",
    fidelity: "Уровень точности",
    tokens: "токенов",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Показать категории",
    all: "ВСЕ",
    ofContext: "контекста использовано",
    insightLabel: "Вывод",
    insight: (tokens, local, free, pro) =>
      `При <span class="white">${tokens} токенах</span> локальная модель 7B с Ollama (2K по умолчанию) тратит <span class="red">${local}</span> своего контекста. Бесплатный ChatGPT — <span class="orange">${free}</span>. Claude Pro — <span class="green">${pro}</span>. Один протокол. Совершенно разная цена.`,
    insightPunch: "Люди с наименьшим контекстным окном получают наибольшую пользу от AIST. Непрерывность не должна быть премиум-функцией.",
    terseTip: (tokens, pct) => `При нотации TERSE даже локальная модель 2K сохраняет состояние сессии всего за <span class="orange">${pct}</span>.`,
    compactTip: "Нотация COMPACT сокращает стоимость вдвое, сохраняя читаемость.",
    fullTip: "Попробуйте COMPACT или TERSE, чтобы увидеть, как уменьшается объём.",
    models: "моделей",
    impact: { TRANSFORMATIVE: "РЕВОЛЮЦИЯ", CRITICAL: "КРИТИЧНО", HIGH: "ВЫСОКИЙ", SIGNIFICANT: "ЗНАЧИМЫЙ", MODERATE: "УМЕРЕННЫЙ", LOW: "НИЗКИЙ", NEGLIGIBLE: "НИЧТОЖНЫЙ" },
    fidLabels: ["Всё сохранено", "Без энергии/ограничений", "Ключевые решения", "Только суть + передача"],
    notLabels: ["Человек + Машина", "Сокращённо", "Телеграфный, для машин"],
    catLabels: {
      "edge": "На устройстве / Edge", "local": "Локально (Ollama / llama.cpp)", "free": "Бесплатный уровень",
      "paid": "Платный ($20/мес)", "pro": "Про / Бизнес", "enterprise": "Корпоративный",
      "api-premium": "API — Премиум", "api-budget": "API — Бюджетный", "self-hosted-max": "Свой хостинг (макс.)"
    },
  },
  ja: {
    lang: "日本語",
    tag: "AISTプロトコル v0.5 · オープンソース · CC BY-SA 4.0",
    title: "コンテキストコスト計算機",
    subtitle: "AISTハンドオフはコンテキストウィンドウのどれくらいを消費しますか？",
    highlight: "コンテキストが小さいほど、AISTの価値は大きくなります。",
    universal: "プレーンテキスト。ベンダーロックインなし。1つのハンドオフがChatGPT、Claude、Gemini、Llama、その他すべてのLLMで機能します。",
    anyModel: "あらゆるLLM",
    notation: "表記密度",
    fidelity: "忠実度レベル",
    tokens: "トークン",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "カテゴリを表示",
    all: "すべて",
    ofContext: "コンテキスト使用率",
    insightLabel: "重要なポイント",
    insight: (tokens, local, free, pro) =>
      `<span class="white">${tokens}トークン</span>で、Ollamaデフォルト2Kのローカル7Bモデルはコンテキスト全体の<span class="red">${local}</span>を支払います。ChatGPT無料ユーザーは<span class="orange">${free}</span>。Claude Proは<span class="green">${pro}</span>。同じプロトコル。大きく異なるコスト。`,
    insightPunch: "最小のコンテキストウィンドウを持つ人々がAISTから最大の恩恵を受けます。継続性はプレミアム機能であるべきではありません。",
    terseTip: (tokens, pct) => `TERSE表記では、2Kローカルモデルでもわずか<span class="orange">${pct}</span>でセッション状態を維持できます。`,
    compactTip: "COMPACT表記はコストを半分にしながら人間の可読性を維持します。",
    fullTip: "COMPACTまたはTERSEに切り替えて、フットプリントの縮小を確認してください。",
    models: "モデル",
    impact: { TRANSFORMATIVE: "革命的", CRITICAL: "重大", HIGH: "高", SIGNIFICANT: "重要", MODERATE: "中程度", LOW: "低", NEGLIGIBLE: "無視可能" },
    fidLabels: ["すべて保存", "エネルギー/制約を削除", "コア決定+スレッド", "要約+ハンドオフのみ"],
    notLabels: ["人間+機械可読", "省略形・スキャン可能", "電文式・機械向け"],
    catLabels: {
      "edge": "デバイス/エッジ", "local": "ローカル (Ollama / llama.cpp)", "free": "無料プラン",
      "paid": "有料 ($20/月)", "pro": "プロ / ビジネス", "enterprise": "エンタープライズ",
      "api-premium": "API — プレミアム", "api-budget": "API — バジェット", "self-hosted-max": "セルフホスト（最大）"
    },
  },
  fr: {
    lang: "Français",
    tag: "Protocole AIST v0.5 · Open Source · CC BY-SA 4.0",
    title: "Calculateur de Coût de Contexte",
    subtitle: "Combien de votre fenêtre de contexte un handoff AIST coûte-t-il réellement ?",
    highlight: "Moins vous avez de contexte, plus AIST compte.",
    universal: "Texte brut. Aucun verrouillage fournisseur. Un seul handoff fonctionne sur ChatGPT, Claude, Gemini, Llama et tout autre LLM.",
    anyModel: "Tout LLM",
    notation: "Densité de Notation",
    fidelity: "Niveau de Fidélité",
    tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Afficher les Catégories",
    all: "TOUTES",
    ofContext: "du contexte utilisé",
    insightLabel: "L'essentiel",
    insight: (tokens, local, free, pro) =>
      `À <span class="white">${tokens} tokens</span>, un modèle local 7B avec Ollama (2K par défaut) consomme <span class="red">${local}</span> de son contexte entier. Un utilisateur gratuit ChatGPT paie <span class="orange">${free}</span>. Claude Pro paie <span class="green">${pro}</span>. Même protocole. Coût très différent.`,
    insightPunch: "Les personnes ayant les plus petites fenêtres de contexte bénéficient le plus d'AIST. La continuité ne devrait pas être une fonctionnalité premium.",
    terseTip: (tokens, pct) => `En notation TERSE, même un modèle local 2K conserve l'état de session pour seulement <span class="orange">${pct}</span>.`,
    compactTip: "La notation COMPACT réduit le coût de moitié tout en restant lisible.",
    fullTip: "Essayez COMPACT ou TERSE pour voir la réduction d'empreinte.",
    models: "modèles",
    impact: { TRANSFORMATIVE: "TRANSFORMATEUR", CRITICAL: "CRITIQUE", HIGH: "ÉLEVÉ", SIGNIFICANT: "SIGNIFICATIF", MODERATE: "MODÉRÉ", LOW: "FAIBLE", NEGLIGIBLE: "NÉGLIGEABLE" },
    fidLabels: ["Tout préservé", "Sans énergie/contraintes", "Décisions + fils", "Essence + handoff uniquement"],
    notLabels: ["Humain + Machine", "Abrégé, scannable", "Télégraphique, pour machines"],
    catLabels: {
      "edge": "Sur appareil / Edge", "local": "Local (Ollama / llama.cpp)", "free": "Gratuit",
      "paid": "Consommateur ($20/mois)", "pro": "Pro / Business", "enterprise": "Entreprise",
      "api-premium": "API — Premium", "api-budget": "API — Économique", "self-hosted-max": "Auto-hébergé (Maximum)"
    },
  },
  de: {
    lang: "Deutsch",
    tag: "AIST-Protokoll v0.5 · Open Source · CC BY-SA 4.0",
    title: "Kontextkosten-Rechner",
    subtitle: "Wie viel Ihres Kontextfensters kostet ein AIST-Handoff?",
    highlight: "Je weniger Kontext Sie haben, desto wichtiger ist AIST.",
    universal: "Klartext. Kein Vendor-Lock-in. Ein Handoff funktioniert mit ChatGPT, Claude, Gemini, Llama und jedem anderen LLM.",
    anyModel: "Jedes LLM",
    notation: "Notationsdichte",
    fidelity: "Genauigkeitsstufe",
    tokens: "Token",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Kategorien anzeigen",
    all: "ALLE",
    ofContext: "des Kontexts genutzt",
    insightLabel: "Das Fazit",
    insight: (tokens, local, free, pro) =>
      `Bei <span class="white">${tokens} Token</span> zahlt ein lokales 7B-Modell mit Ollama (2K Standard) <span class="red">${local}</span> seines gesamten Kontexts. Ein kostenloser ChatGPT-Nutzer zahlt <span class="orange">${free}</span>. Claude Pro zahlt <span class="green">${pro}</span>. Gleiches Protokoll. Sehr unterschiedliche Kosten.`,
    insightPunch: "Menschen mit den kleinsten Kontextfenstern profitieren am meisten von AIST. Kontinuität sollte kein Premium-Feature sein.",
    terseTip: (tokens, pct) => `Bei TERSE-Notation behält selbst ein 2K-Modell den Sitzungsstatus für nur <span class="orange">${pct}</span>.`,
    compactTip: "COMPACT-Notation halbiert die Kosten bei Beibehaltung der Lesbarkeit.",
    fullTip: "Versuchen Sie COMPACT oder TERSE, um die Reduzierung zu sehen.",
    models: "Modelle",
    impact: { TRANSFORMATIVE: "TRANSFORMATIV", CRITICAL: "KRITISCH", HIGH: "HOCH", SIGNIFICANT: "BEDEUTSAM", MODERATE: "MODERAT", LOW: "NIEDRIG", NEGLIGIBLE: "VERNACHLÄSSIGBAR" },
    fidLabels: ["Alles erhalten", "Ohne Energie/Einschränkungen", "Kernentscheidungen + Threads", "Nur Essenz + Handoff"],
    notLabels: ["Mensch + Maschine lesbar", "Abgekürzt, scannbar", "Telegrafisch, maschinenfokussiert"],
    catLabels: {
      "edge": "Auf dem Gerät / Edge", "local": "Lokal (Ollama / llama.cpp)", "free": "Kostenlos",
      "paid": "Bezahlt ($20/Monat)", "pro": "Pro / Business", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Budget", "self-hosted-max": "Selbst gehostet (Maximum)"
    },
  },
  ko: {
    lang: "한국어",
    tag: "AIST 프로토콜 v0.5 · 오픈 소스 · CC BY-SA 4.0",
    title: "컨텍스트 비용 계산기",
    subtitle: "AIST 핸드오프가 컨텍스트 윈도우를 얼마나 차지할까요?",
    highlight: "컨텍스트가 적을수록 AIST의 가치는 커집니다.",
    universal: "플레인 텍스트. 벤더 종속 없음. 하나의 핸드오프가 ChatGPT, Claude, Gemini, Llama 등 모든 LLM에서 작동합니다.",
    anyModel: "모든 LLM",
    notation: "표기 밀도",
    fidelity: "충실도 수준",
    tokens: "토큰",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "카테고리 표시",
    all: "전체",
    ofContext: "컨텍스트 사용",
    insightLabel: "핵심 요점",
    insight: (tokens, local, free, pro) =>
      `<span class="white">${tokens} 토큰</span>에서 Ollama 기본 2K의 로컬 7B 모델은 전체 컨텍스트의 <span class="red">${local}</span>을 사용합니다. ChatGPT 무료 사용자는 <span class="orange">${free}</span>. Claude Pro는 <span class="green">${pro}</span>. 같은 프로토콜. 매우 다른 비용.`,
    insightPunch: "가장 작은 컨텍스트 윈도우를 가진 사람들이 AIST에서 가장 큰 혜택을 받습니다. 연속성은 프리미엄 기능이 아니어야 합니다.",
    terseTip: (tokens, pct) => `TERSE 표기법에서 2K 로컬 모델도 단 <span class="orange">${pct}</span>으로 세션 상태를 유지합니다.`,
    compactTip: "COMPACT 표기법은 비용을 절반으로 줄이면서 가독성을 유지합니다.",
    fullTip: "COMPACT 또는 TERSE로 전환하여 풋프린트 감소를 확인해 보세요.",
    models: "모델",
    impact: { TRANSFORMATIVE: "혁신적", CRITICAL: "중대", HIGH: "높음", SIGNIFICANT: "중요", MODERATE: "보통", LOW: "낮음", NEGLIGIBLE: "무시 가능" },
    fidLabels: ["모두 보존", "에너지/제약 제거", "핵심 결정 + 스레드", "요약 + 핸드오프만"],
    notLabels: ["사람 + 기계 가독", "축약, 스캔 가능", "전보식, 기계 중심"],
    catLabels: {
      "edge": "기기 / 엣지", "local": "로컬 (Ollama / llama.cpp)", "free": "무료",
      "paid": "유료 ($20/월)", "pro": "프로 / 비즈니스", "enterprise": "엔터프라이즈",
      "api-premium": "API — 프리미엄", "api-budget": "API — 버짓", "self-hosted-max": "셀프 호스팅 (최대)"
    },
  },
  id: {
    lang: "Bahasa Indonesia",
    tag: "Protokol AIST v0.5 · Sumber Terbuka · CC BY-SA 4.0",
    title: "Kalkulator Biaya Konteks",
    subtitle: "Berapa banyak jendela konteks Anda yang digunakan oleh handoff AIST?",
    highlight: "Semakin kecil konteks Anda, semakin penting AIST.",
    universal: "Teks biasa. Tanpa vendor lock-in. Satu handoff berfungsi di ChatGPT, Claude, Gemini, Llama, dan semua LLM lainnya.",
    anyModel: "Semua LLM",
    notation: "Kepadatan Notasi",
    fidelity: "Tingkat Fidelitas",
    tokens: "token",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Tampilkan Kategori",
    all: "SEMUA",
    ofContext: "konteks terpakai",
    insightLabel: "Kesimpulan",
    insight: (tokens, local, free, pro) =>
      `Pada <span class="white">${tokens} token</span>, model lokal 7B dengan Ollama (default 2K) membayar <span class="red">${local}</span> dari seluruh konteksnya. Pengguna gratis ChatGPT membayar <span class="orange">${free}</span>. Claude Pro membayar <span class="green">${pro}</span>. Protokol sama. Biaya sangat berbeda.`,
    insightPunch: "Orang dengan jendela konteks terkecil mendapat manfaat terbesar dari AIST. Kontinuitas seharusnya bukan fitur premium.",
    terseTip: (tokens, pct) => `Dengan notasi TERSE, model lokal 2K hanya butuh <span class="orange">${pct}</span> untuk menyimpan state sesi.`,
    compactTip: "Notasi COMPACT memotong biaya setengah sambil tetap bisa dibaca manusia.",
    fullTip: "Coba beralih ke COMPACT atau TERSE untuk melihat penurunan ukuran.",
    models: "model",
    impact: { TRANSFORMATIVE: "TRANSFORMATIF", CRITICAL: "KRITIS", HIGH: "TINGGI", SIGNIFICANT: "SIGNIFIKAN", MODERATE: "SEDANG", LOW: "RENDAH", NEGLIGIBLE: "DAPAT DIABAIKAN" },
    fidLabels: ["Semua tersimpan", "Tanpa energi/batasan", "Keputusan inti + thread", "Hanya esensi + handoff"],
    notLabels: ["Manusia + Mesin", "Disingkat, bisa discan", "Telegrafis, untuk mesin"],
    catLabels: {
      "edge": "Di Perangkat / Edge", "local": "Lokal (Ollama / llama.cpp)", "free": "Gratis",
      "paid": "Berbayar ($20/bln)", "pro": "Pro / Bisnis", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Hemat", "self-hosted-max": "Self-hosted (Maks)"
    },
  },
  tr: {
    lang: "Türkçe",
    tag: "AIST Protokolü v0.5 · Açık Kaynak · CC BY-SA 4.0",
    title: "Bağlam Maliyet Hesaplayıcı",
    subtitle: "Bir AIST devir işlemi bağlam pencerenizin ne kadarını kullanır?",
    highlight: "Bağlamınız ne kadar azsa, AIST o kadar önemli.",
    universal: "Düz metin. Satıcı bağımlılığı yok. Tek bir devir ChatGPT, Claude, Gemini, Llama ve diğer tüm LLM'lerde çalışır.",
    anyModel: "Her LLM",
    notation: "Notasyon Yoğunluğu", fidelity: "Doğruluk Seviyesi", tokens: "token",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Kategorileri Göster", all: "TÜMÜ", ofContext: "bağlam kullanıldı",
    insightLabel: "Sonuç",
    insight: (tokens, local, free, pro) =>
      `<span class="white">${tokens} token</span> ile Ollama varsayılan 2K yerel 7B model tüm bağlamının <span class="red">${local}</span>'ini öder. Ücretsiz ChatGPT kullanıcısı <span class="orange">${free}</span>. Claude Pro <span class="green">${pro}</span>. Aynı protokol. Çok farklı maliyet.`,
    insightPunch: "En küçük bağlam penceresine sahip kişiler AIST'ten en çok faydalanır. Süreklilik premium bir özellik olmamalıdır.",
    terseTip: (tokens, pct) => `TERSE notasyonunda 2K yerel model bile sadece <span class="orange">${pct}</span> ile oturum durumunu korur.`,
    compactTip: "COMPACT notasyonu maliyeti yarıya indirirken okunabilirliği korur.",
    fullTip: "Ayak izinin ne kadar küçüldüğünü görmek için COMPACT veya TERSE'e geçin.",
    models: "model",
    impact: { TRANSFORMATIVE: "DÖNÜŞTÜRÜCÜ", CRITICAL: "KRİTİK", HIGH: "YÜKSEK", SIGNIFICANT: "ÖNEMLİ", MODERATE: "ORTA", LOW: "DÜŞÜK", NEGLIGIBLE: "İHMAL EDİLEBİLİR" },
    fidLabels: ["Her şey korundu", "Enerji/kısıtlamalar çıkarıldı", "Temel kararlar + konular", "Sadece özet + devir"],
    notLabels: ["İnsan + Makine okunabilir", "Kısaltılmış, taranabilir", "Telgraf, makine odaklı"],
    catLabels: {
      "edge": "Cihazda / Edge", "local": "Yerel (Ollama / llama.cpp)", "free": "Ücretsiz",
      "paid": "Ücretli ($20/ay)", "pro": "Pro / İş", "enterprise": "Kurumsal",
      "api-premium": "API — Premium", "api-budget": "API — Bütçe", "self-hosted-max": "Kendi Sunucu (Maks)"
    },
  },
  vi: {
    lang: "Tiếng Việt",
    tag: "Giao thức AIST v0.5 · Mã nguồn mở · CC BY-SA 4.0",
    title: "Máy Tính Chi Phí Ngữ Cảnh",
    subtitle: "Handoff AIST chiếm bao nhiêu cửa sổ ngữ cảnh của bạn?",
    highlight: "Ngữ cảnh càng nhỏ, AIST càng có giá trị.",
    universal: "Văn bản thuần. Không phụ thuộc nhà cung cấp. Một handoff hoạt động trên ChatGPT, Claude, Gemini, Llama và mọi LLM khác.",
    anyModel: "Mọi LLM",
    notation: "Mật độ ký hiệu", fidelity: "Mức độ trung thực", tokens: "token",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Hiện danh mục", all: "TẤT CẢ", ofContext: "ngữ cảnh đã dùng",
    insightLabel: "Kết luận",
    insight: (tokens, local, free, pro) =>
      `Với <span class="white">${tokens} token</span>, mô hình 7B chạy local với Ollama (mặc định 2K) tốn <span class="red">${local}</span> toàn bộ ngữ cảnh. Người dùng ChatGPT miễn phí tốn <span class="orange">${free}</span>. Claude Pro tốn <span class="green">${pro}</span>. Cùng giao thức. Chi phí rất khác.`,
    insightPunch: "Những người có cửa sổ ngữ cảnh nhỏ nhất được hưởng lợi nhiều nhất từ AIST. Tính liên tục không nên là tính năng trả phí.",
    terseTip: (tokens, pct) => `Với ký hiệu TERSE, mô hình local 2K chỉ tốn <span class="orange">${pct}</span> cho trạng thái phiên.`,
    compactTip: "Ký hiệu COMPACT giảm chi phí một nửa mà vẫn đọc được.",
    fullTip: "Hãy thử COMPACT hoặc TERSE để xem dung lượng giảm bao nhiêu.",
    models: "mô hình",
    impact: { TRANSFORMATIVE: "CÁCH MẠNG", CRITICAL: "QUAN TRỌNG", HIGH: "CAO", SIGNIFICANT: "ĐÁNG KỂ", MODERATE: "VỪA", LOW: "THẤP", NEGLIGIBLE: "KHÔNG ĐÁNG KỂ" },
    fidLabels: ["Giữ tất cả", "Bỏ năng lượng/ràng buộc", "Quyết định chính + luồng", "Chỉ bản chất + handoff"],
    notLabels: ["Người + Máy đọc được", "Viết tắt, quét được", "Điện tín, cho máy"],
    catLabels: {
      "edge": "Trên thiết bị / Edge", "local": "Local (Ollama / llama.cpp)", "free": "Miễn phí",
      "paid": "Trả phí ($20/tháng)", "pro": "Pro / Doanh nghiệp", "enterprise": "Enterprise",
      "api-premium": "API — Cao cấp", "api-budget": "API — Tiết kiệm", "self-hosted-max": "Tự host (Tối đa)"
    },
  },
  th: {
    lang: "ไทย",
    tag: "โปรโตคอล AIST v0.5 · โอเพนซอร์ส · CC BY-SA 4.0",
    title: "เครื่องคำนวณต้นทุน Context",
    subtitle: "AIST handoff ใช้ context window ของคุณเท่าไร?",
    highlight: "ยิ่ง context น้อย AIST ยิ่งมีคุณค่า",
    universal: "ข้อความธรรมดา ไม่ผูกกับผู้ให้บริการ handoff เดียวใช้ได้กับ ChatGPT, Claude, Gemini, Llama และ LLM อื่นทุกตัว",
    anyModel: "ทุก LLM",
    notation: "ความหนาแน่น", fidelity: "ระดับความเที่ยงตรง", tokens: "โทเค็น",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "แสดงหมวดหมู่", all: "ทั้งหมด", ofContext: "ของ context ที่ใช้",
    insightLabel: "บทสรุป",
    insight: (tokens, local, free, pro) =>
      `ที่ <span class="white">${tokens} โทเค็น</span> โมเดล 7B ในเครื่อง (Ollama 2K) ใช้ <span class="red">${local}</span> ของ context ทั้งหมด ChatGPT ฟรีใช้ <span class="orange">${free}</span> Claude Pro ใช้ <span class="green">${pro}</span> โปรโตคอลเดียวกัน ต้นทุนต่างมาก`,
    insightPunch: "คนที่มี context window เล็กที่สุด ได้ประโยชน์จาก AIST มากที่สุด ความต่อเนื่องไม่ควรเป็นฟีเจอร์พรีเมียม",
    terseTip: (tokens, pct) => `ในรูปแบบ TERSE โมเดล 2K ใช้เพียง <span class="orange">${pct}</span> เก็บสถานะเซสชัน`,
    compactTip: "รูปแบบ COMPACT ลดต้นทุนครึ่งหนึ่งโดยยังอ่านได้",
    fullTip: "ลองสลับไป COMPACT หรือ TERSE เพื่อดูขนาดที่ลดลง",
    models: "โมเดล",
    impact: { TRANSFORMATIVE: "ปฏิวัติ", CRITICAL: "สำคัญมาก", HIGH: "สูง", SIGNIFICANT: "สำคัญ", MODERATE: "ปานกลาง", LOW: "ต่ำ", NEGLIGIBLE: "น้อยมาก" },
    fidLabels: ["เก็บทั้งหมด", "ตัดพลังงาน/ข้อจำกัด", "การตัดสินใจหลัก", "แค่สาระ + handoff"],
    notLabels: ["คน + เครื่องอ่านได้", "ย่อ สแกนได้", "โทรเลข สำหรับเครื่อง"],
    catLabels: {
      "edge": "บนอุปกรณ์ / Edge", "local": "ในเครื่อง (Ollama)", "free": "ฟรี",
      "paid": "เสียเงิน ($20/เดือน)", "pro": "Pro / ธุรกิจ", "enterprise": "องค์กร",
      "api-premium": "API — พรีเมียม", "api-budget": "API — ประหยัด", "self-hosted-max": "โฮสต์เอง (สูงสุด)"
    },
  },
  it: {
    lang: "Italiano",
    tag: "Protocollo AIST v0.5 · Open Source · CC BY-SA 4.0",
    title: "Calcolatore Costo Contesto",
    subtitle: "Quanto della tua finestra di contesto consuma un handoff AIST?",
    highlight: "Meno contesto hai, più AIST conta.",
    universal: "Testo semplice. Nessun vendor lock-in. Un solo handoff funziona su ChatGPT, Claude, Gemini, Llama e qualsiasi altro LLM.",
    anyModel: "Qualsiasi LLM",
    notation: "Densità Notazione", fidelity: "Livello Fedeltà", tokens: "token",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Mostra Categorie", all: "TUTTE", ofContext: "del contesto usato",
    insightLabel: "La Conclusione",
    insight: (tokens, local, free, pro) =>
      `Con <span class="white">${tokens} token</span>, un modello locale 7B con Ollama (2K default) consuma <span class="red">${local}</span> dell'intero contesto. Un utente gratuito ChatGPT paga <span class="orange">${free}</span>. Claude Pro paga <span class="green">${pro}</span>. Stesso protocollo. Costo molto diverso.`,
    insightPunch: "Le persone con le finestre di contesto più piccole ottengono il maggior beneficio da AIST. La continuità non dovrebbe essere una funzione premium.",
    terseTip: (tokens, pct) => `Con notazione TERSE, anche un modello locale 2K mantiene lo stato sessione per solo <span class="orange">${pct}</span>.`,
    compactTip: "La notazione COMPACT dimezza il costo mantenendo la leggibilità.",
    fullTip: "Prova COMPACT o TERSE per vedere la riduzione dell'impronta.",
    models: "modelli",
    impact: { TRANSFORMATIVE: "TRASFORMATIVO", CRITICAL: "CRITICO", HIGH: "ALTO", SIGNIFICANT: "SIGNIFICATIVO", MODERATE: "MODERATO", LOW: "BASSO", NEGLIGIBLE: "TRASCURABILE" },
    fidLabels: ["Tutto preservato", "Senza energia/vincoli", "Decisioni + thread", "Solo essenza + handoff"],
    notLabels: ["Umano + Macchina", "Abbreviato, scansionabile", "Telegrafico, per macchine"],
    catLabels: {
      "edge": "Sul Dispositivo / Edge", "local": "Locale (Ollama / llama.cpp)", "free": "Gratuito",
      "paid": "A pagamento ($20/mese)", "pro": "Pro / Business", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Economica", "self-hosted-max": "Self-hosted (Massimo)"
    },
  },
  pl: {
    lang: "Polski",
    tag: "Protokół AIST v0.5 · Otwarte źródło · CC BY-SA 4.0",
    title: "Kalkulator Kosztu Kontekstu",
    subtitle: "Ile okna kontekstowego zajmuje handoff AIST?",
    highlight: "Im mniej kontekstu, tym AIST ważniejszy.",
    universal: "Zwykły tekst. Bez uzależnienia od dostawcy. Jeden handoff działa na ChatGPT, Claude, Gemini, Llama i każdym innym LLM.",
    anyModel: "Każdy LLM",
    notation: "Gęstość notacji", fidelity: "Poziom wierności", tokens: "tokenów",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Pokaż kategorie", all: "WSZYSTKIE", ofContext: "kontekstu użyto",
    insightLabel: "Wniosek",
    insight: (tokens, local, free, pro) =>
      `Przy <span class="white">${tokens} tokenach</span> lokalny model 7B z Ollama (domyślne 2K) zużywa <span class="red">${local}</span> całego kontekstu. Darmowy ChatGPT: <span class="orange">${free}</span>. Claude Pro: <span class="green">${pro}</span>. Ten sam protokół. Zupełnie inny koszt.`,
    insightPunch: "Osoby z najmniejszymi oknami kontekstowymi odnoszą największe korzyści z AIST. Ciągłość nie powinna być funkcją premium.",
    terseTip: (tokens, pct) => `W notacji TERSE nawet lokalny model 2K utrzymuje stan sesji za jedyne <span class="orange">${pct}</span>.`,
    compactTip: "Notacja COMPACT zmniejsza koszt o połowę, zachowując czytelność.",
    fullTip: "Spróbuj COMPACT lub TERSE, żeby zobaczyć redukcję rozmiaru.",
    models: "modeli",
    impact: { TRANSFORMATIVE: "REWOLUCYJNY", CRITICAL: "KRYTYCZNY", HIGH: "WYSOKI", SIGNIFICANT: "ISTOTNY", MODERATE: "UMIARKOWANY", LOW: "NISKI", NEGLIGIBLE: "POMIJALNY" },
    fidLabels: ["Wszystko zachowane", "Bez energii/ograniczeń", "Kluczowe decyzje + wątki", "Tylko esencja + handoff"],
    notLabels: ["Człowiek + Maszyna", "Skrócone, skanowalne", "Telegraficzne, dla maszyn"],
    catLabels: {
      "edge": "Na urządzeniu / Edge", "local": "Lokalnie (Ollama / llama.cpp)", "free": "Darmowy",
      "paid": "Płatny ($20/mies.)", "pro": "Pro / Biznes", "enterprise": "Korporacyjny",
      "api-premium": "API — Premium", "api-budget": "API — Budżetowy", "self-hosted-max": "Self-hosted (Maks)"
    },
  },
  uk: {
    lang: "Українська",
    tag: "Протокол AIST v0.5 · Відкритий код · CC BY-SA 4.0",
    title: "Калькулятор вартості контексту",
    subtitle: "Скільки контекстного вікна займає передача AIST?",
    highlight: "Чим менше контексту, тим важливіший AIST.",
    universal: "Звичайний текст. Без прив'язки до вендора. Одна передача працює на ChatGPT, Claude, Gemini, Llama та будь-якій іншій LLM.",
    anyModel: "Будь-яка LLM",
    notation: "Щільність нотації", fidelity: "Рівень точності", tokens: "токенів",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Показати категорії", all: "ВСІ", ofContext: "контексту використано",
    insightLabel: "Висновок",
    insight: (tokens, local, free, pro) =>
      `При <span class="white">${tokens} токенах</span> локальна модель 7B з Ollama (2K за замовчуванням) витрачає <span class="red">${local}</span> всього контексту. Безкоштовний ChatGPT: <span class="orange">${free}</span>. Claude Pro: <span class="green">${pro}</span>. Один протокол. Дуже різна ціна.`,
    insightPunch: "Люди з найменшим контекстним вікном отримують найбільшу користь від AIST. Безперервність не повинна бути преміум-функцією.",
    terseTip: (tokens, pct) => `При нотації TERSE навіть 2K модель зберігає стан сесії лише за <span class="orange">${pct}</span>.`,
    compactTip: "Нотація COMPACT вдвічі зменшує вартість, зберігаючи читабельність.",
    fullTip: "Спробуйте COMPACT або TERSE, щоб побачити зменшення.",
    models: "моделей",
    impact: { TRANSFORMATIVE: "РЕВОЛЮЦІЙНИЙ", CRITICAL: "КРИТИЧНИЙ", HIGH: "ВИСОКИЙ", SIGNIFICANT: "ЗНАЧНИЙ", MODERATE: "ПОМІРНИЙ", LOW: "НИЗЬКИЙ", NEGLIGIBLE: "МІЗЕРНИЙ" },
    fidLabels: ["Все збережено", "Без енергії/обмежень", "Ключові рішення + потоки", "Тільки суть + передача"],
    notLabels: ["Людина + Машина", "Скорочено", "Телеграфний, для машин"],
    catLabels: {
      "edge": "На пристрої / Edge", "local": "Локально (Ollama / llama.cpp)", "free": "Безкоштовний",
      "paid": "Платний ($20/міс)", "pro": "Про / Бізнес", "enterprise": "Корпоративний",
      "api-premium": "API — Преміум", "api-budget": "API — Бюджетний", "self-hosted-max": "Свій хостинг (макс.)"
    },
  },
  sw: {
    lang: "Kiswahili",
    tag: "Itifaki ya AIST v0.5 · Chanzo Huria · CC BY-SA 4.0",
    title: "Kikokotoo cha Gharama ya Muktadha",
    subtitle: "AIST handoff inatumia kiasi gani cha dirisha lako la muktadha?",
    highlight: "Muktadha wako ukiwa mdogo zaidi, AIST inakuwa muhimu zaidi.",
    universal: "Maandishi wazi. Hakuna kufungwa na mtoaji. Handoff moja inafanya kazi kwenye ChatGPT, Claude, Gemini, Llama na LLM nyingine yoyote.",
    anyModel: "LLM yoyote",
    notation: "Msongamano wa Nukuu", fidelity: "Kiwango cha Uaminifu", tokens: "tokeni",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Onyesha Makundi", all: "YOTE", ofContext: "ya muktadha uliotumika",
    insightLabel: "Hitimisho",
    insight: (tokens, local, free, pro) =>
      `Kwa <span class="white">tokeni ${tokens}</span>, modeli ya ndani 7B na Ollama (chaguo-msingi 2K) inatumia <span class="red">${local}</span> ya muktadha wake wote. Mtumiaji wa bure wa ChatGPT: <span class="orange">${free}</span>. Claude Pro: <span class="green">${pro}</span>. Itifaki sawa. Gharama tofauti sana.`,
    insightPunch: "Watu wenye madirisha madogo zaidi ya muktadha wanafaidika zaidi na AIST. Mwendelezo haupaswi kuwa kipengele cha malipo.",
    terseTip: (tokens, pct) => `Kwa nukuu ya TERSE, hata modeli ya ndani ya 2K inahifadhi hali ya kikao kwa <span class="orange">${pct}</span> tu.`,
    compactTip: "Nukuu ya COMPACT inapunguza gharama nusu huku ikibaki inasomeka.",
    fullTip: "Jaribu COMPACT au TERSE kuona kupungua kwa ukubwa.",
    models: "modeli",
    impact: { TRANSFORMATIVE: "KUBADILISHA", CRITICAL: "MUHIMU SANA", HIGH: "JUU", SIGNIFICANT: "MUHIMU", MODERATE: "WASTANI", LOW: "CHINI", NEGLIGIBLE: "NDOGO SANA" },
    fidLabels: ["Yote yamehifadhiwa", "Bila nishati/vikwazo", "Maamuzi muhimu + nyuzi", "Kiini + handoff tu"],
    notLabels: ["Binadamu + Mashine", "Kifupi, inaskanwa", "Telegrafi, kwa mashine"],
    catLabels: {
      "edge": "Kwenye Kifaa / Edge", "local": "Ndani (Ollama / llama.cpp)", "free": "Bure",
      "paid": "Iliyolipwa ($20/mwezi)", "pro": "Pro / Biashara", "enterprise": "Shirika",
      "api-premium": "API — Premium", "api-budget": "API — Bajeti", "self-hosted-max": "Kujihifadhi (Upeo)"
    },
  },
  sv: {
    lang: "Svenska",
    tag: "AIST-protokollet v0.5 · Öppen källkod · CC BY-SA 4.0",
    title: "Kontextkostnadskalkylator",
    subtitle: "Hur mycket av ditt kontextfönster kostar en AIST-överlämning?",
    highlight: "Ju mindre kontext du har, desto viktigare är AIST.",
    universal: "Ren text. Ingen leverantörsinlåsning. En överlämning fungerar på ChatGPT, Claude, Gemini, Llama och alla andra LLM:er.",
    anyModel: "Alla LLM:er",
    notation: "Notationstäthet", fidelity: "Noggrannhetsnivå", tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Visa kategorier", all: "ALLA", ofContext: "av kontext använt",
    insightLabel: "Slutsatsen",
    insight: (tokens, local, free, pro) =>
      `Vid <span class="white">${tokens} tokens</span> betalar en lokal 7B-modell med Ollama (2K standard) <span class="red">${local}</span> av hela sitt kontextfönster. En gratis ChatGPT-användare betalar <span class="orange">${free}</span>. Claude Pro betalar <span class="green">${pro}</span>. Samma protokoll. Väldigt olika kostnad.`,
    insightPunch: "De med minst kontextfönster får störst nytta av AIST. Kontinuitet borde inte vara en premiumfunktion.",
    terseTip: (tokens, pct) => `Med TERSE-notation behåller även en 2K lokal modell sessionstillstånd för bara <span class="orange">${pct}</span>.`,
    compactTip: "COMPACT-notation halverar kostnaden och behåller läsbarheten.",
    fullTip: "Prova COMPACT eller TERSE för att se hur avtrycket minskar.",
    models: "modeller",
    impact: { TRANSFORMATIVE: "OMVÄLVANDE", CRITICAL: "KRITISK", HIGH: "HÖG", SIGNIFICANT: "BETYDANDE", MODERATE: "MÅTTLIG", LOW: "LÅG", NEGLIGIBLE: "FÖRSUMBAR" },
    fidLabels: ["Allt bevarat", "Utan energi/begränsningar", "Kärnbeslut + trådar", "Bara essens + överlämning"],
    notLabels: ["Människa + Maskin", "Förkortad, skannbar", "Telegrafisk, maskinanpassad"],
    catLabels: {
      "edge": "På enheten / Edge", "local": "Lokal (Ollama / llama.cpp)", "free": "Gratis",
      "paid": "Betald ($20/mån)", "pro": "Pro / Företag", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Budget", "self-hosted-max": "Egen hosting (Max)"
    },
  },
  bn: {
    lang: "বাংলা",
    tag: "AIST প্রোটোকল v0.5 · ওপেন সোর্স · CC BY-SA 4.0",
    title: "কনটেক্সট খরচ ক্যালকুলেটর",
    subtitle: "AIST হ্যান্ডঅফ আপনার কনটেক্সট উইন্ডোর কতটুকু ব্যবহার করে?",
    highlight: "কনটেক্সট যত কম, AIST তত গুরুত্বপূর্ণ।",
    universal: "সাধারণ টেক্সট। কোনো ভেন্ডর লক-ইন নেই। একটি হ্যান্ডঅফ ChatGPT, Claude, Gemini, Llama এবং অন্য সব LLM-এ কাজ করে।",
    anyModel: "যেকোনো LLM",
    notation: "নোটেশন ঘনত্ব", fidelity: "বিশ্বস্ততার স্তর", tokens: "টোকেন",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "বিভাগ দেখান", all: "সব", ofContext: "কনটেক্সট ব্যবহৃত",
    insightLabel: "মূল বার্তা",
    insight: (tokens, local, free, pro) =>
      `<span class="white">${tokens} টোকেনে</span>, Ollama ডিফল্ট 2K সহ লোকাল 7B মডেল পুরো কনটেক্সটের <span class="red">${local}</span> ব্যয় করে। বিনামূল্যে ChatGPT ব্যবহারকারী <span class="orange">${free}</span>। Claude Pro <span class="green">${pro}</span>। একই প্রোটোকল। সম্পূর্ণ ভিন্ন খরচ।`,
    insightPunch: "সবচেয়ে ছোট কনটেক্সট উইন্ডো যাদের, তারাই AIST থেকে সবচেয়ে বেশি উপকৃত হন। ধারাবাহিকতা প্রিমিয়াম ফিচার হওয়া উচিত নয়।",
    terseTip: (tokens, pct) => `TERSE নোটেশনে, 2K লোকাল মডেলও মাত্র <span class="orange">${pct}</span>-এ সেশন স্টেট রাখে।`,
    compactTip: "COMPACT নোটেশন খরচ অর্ধেক করে এবং পাঠযোগ্য রাখে।",
    fullTip: "COMPACT বা TERSE-এ যান, দেখুন ফুটপ্রিন্ট কতটা কমে।",
    models: "মডেল",
    impact: { TRANSFORMATIVE: "রূপান্তরকারী", CRITICAL: "গুরুত্বপূর্ণ", HIGH: "উচ্চ", SIGNIFICANT: "তাৎপর্যপূর্ণ", MODERATE: "মাঝারি", LOW: "কম", NEGLIGIBLE: "নগণ্য" },
    fidLabels: ["সব সংরক্ষিত", "এনার্জি/সীমাবদ্ধতা বাদ", "মূল সিদ্ধান্ত + থ্রেড", "শুধু সার + হ্যান্ডঅফ"],
    notLabels: ["মানুষ + মেশিন পাঠযোগ্য", "সংক্ষিপ্ত, স্ক্যানযোগ্য", "টেলিগ্রাফিক, মেশিন-কেন্দ্রিক"],
    catLabels: {
      "edge": "ডিভাইসে / Edge", "local": "লোকাল (Ollama / llama.cpp)", "free": "বিনামূল্যে",
      "paid": "পেইড ($20/মাস)", "pro": "প্রো / ব্যবসা", "enterprise": "এন্টারপ্রাইজ",
      "api-premium": "API — প্রিমিয়াম", "api-budget": "API — বাজেট", "self-hosted-max": "সেলফ-হোস্টেড (সর্বোচ্চ)"
    },
  },
  nl: {
    lang: "Nederlands",
    tag: "AIST Protocol v0.5 · Open Source · CC BY-SA 4.0",
    title: "Context Kosten Calculator",
    subtitle: "Hoeveel van je contextvenster kost een AIST-handoff?",
    highlight: "Hoe minder context je hebt, hoe meer AIST ertoe doet.",
    universal: "Platte tekst. Geen vendor lock-in. Eén handoff werkt op ChatGPT, Claude, Gemini, Llama en elk ander LLM.",
    anyModel: "Elk LLM",
    notation: "Notatie Dichtheid", fidelity: "Betrouwbaarheidsniveau", tokens: "tokens",
    tokenMeta: (n, f) => `${n.label} · ${f.label}`,
    showCats: "Toon Categorieën", all: "ALLE", ofContext: "van context gebruikt",
    insightLabel: "De Conclusie",
    insight: (tokens, local, free, pro) =>
      `Bij <span class="white">${tokens} tokens</span> betaalt een lokaal 7B-model met Ollama (2K standaard) <span class="red">${local}</span> van zijn hele context. Een gratis ChatGPT-gebruiker betaalt <span class="orange">${free}</span>. Claude Pro betaalt <span class="green">${pro}</span>. Zelfde protocol. Heel andere kosten.`,
    insightPunch: "Mensen met de kleinste contextvensters profiteren het meest van AIST. Continuïteit zou geen premium-functie moeten zijn.",
    terseTip: (tokens, pct) => `Met TERSE-notatie behoudt zelfs een 2K lokaal model sessiestatus voor slechts <span class="orange">${pct}</span>.`,
    compactTip: "COMPACT-notatie halveert de kosten en blijft leesbaar.",
    fullTip: "Probeer COMPACT of TERSE om de reductie te zien.",
    models: "modellen",
    impact: { TRANSFORMATIVE: "TRANSFORMATIEF", CRITICAL: "KRITIEK", HIGH: "HOOG", SIGNIFICANT: "SIGNIFICANT", MODERATE: "MATIG", LOW: "LAAG", NEGLIGIBLE: "VERWAARLOOSBAAR" },
    fidLabels: ["Alles bewaard", "Zonder energie/beperkingen", "Kernbeslissingen + threads", "Alleen essentie + handoff"],
    notLabels: ["Mens + Machine", "Afgekort, scanbaar", "Telegrafisch, voor machines"],
    catLabels: {
      "edge": "Op apparaat / Edge", "local": "Lokaal (Ollama / llama.cpp)", "free": "Gratis",
      "paid": "Betaald ($20/mnd)", "pro": "Pro / Zakelijk", "enterprise": "Enterprise",
      "api-premium": "API — Premium", "api-budget": "API — Budget", "self-hosted-max": "Zelf gehost (Max)"
    },
  },
};

// Detect browser language, fallback to English
function detectLang() {
  const nav = navigator.language || navigator.userLanguage || 'en';
  const short = nav.split('-')[0];
  return T[short] ? short : 'en';
}

const MODELS = [
  // ON-DEVICE / EDGE
  { name: "Gemini Nano (on-device)", ctx: 4096, cat: "edge", access: "Built into Android/Chrome", note: "On-device, no cloud" },
  { name: "Llama 3.2 1B (mobile)", ctx: 4096, cat: "edge", access: "Free (your device)" },
  { name: "Phi-3 Mini (on-device)", ctx: 4096, cat: "edge", access: "Free (your device)" },
  { name: "Gemma 3n E4B (mobile)", ctx: 4096, cat: "edge", access: "Free (your device)" },

  // LOCAL OLLAMA / LLAMA.CPP
  { name: "Any model, Ollama default", ctx: 2048, cat: "local", access: "Free (your GPU)", note: "Ollama ships with 2K default" },
  { name: "Mistral 7B (4K)", ctx: 4096, cat: "local", access: "Free · 8GB VRAM" },
  { name: "Llama 3.1 8B (4K)", ctx: 4096, cat: "local", access: "Free · 8GB VRAM" },
  { name: "Qwen3 8B (4K default)", ctx: 4096, cat: "local", access: "Free · 8GB VRAM", note: "Max 40K, but 4K default" },
  { name: "DeepSeek R1 8B (4K)", ctx: 4096, cat: "local", access: "Free · 8GB VRAM" },
  { name: "Any 7B model (8K configured)", ctx: 8192, cat: "local", access: "Free · 8GB VRAM" },
  { name: "Gemma 3 12B (8K)", ctx: 8192, cat: "local", access: "Free · 12GB VRAM" },
  { name: "Qwen3 14B (8K)", ctx: 8192, cat: "local", access: "Free · 12GB VRAM" },
  { name: "Gemma 3 27B (4K)", ctx: 4096, cat: "local", access: "Free · 24GB VRAM" },
  { name: "Qwen3 32B (8K)", ctx: 8192, cat: "local", access: "Free · 24GB VRAM" },
  { name: "DeepSeek R1 32B (8K)", ctx: 8192, cat: "local", access: "Free · 24GB VRAM" },
  { name: "Llama 3.3 70B (4K)", ctx: 4096, cat: "local", access: "Free · 48GB+ VRAM" },
  { name: "Llama 3.3 70B (8K)", ctx: 8192, cat: "local", access: "Free · 2x 24GB VRAM" },
  { name: "Any 7B model (32K stretched)", ctx: 32768, cat: "local", access: "Free · 16GB VRAM", note: "Rope scaling, quality may degrade" },

  // FREE TIERS
  { name: "ChatGPT Free (GPT-5.2)", ctx: 8000, cat: "free", access: "Free", note: "10 msgs / 5 hrs" },
  { name: "ChatGPT Free (fallback mini)", ctx: 8000, cat: "free", access: "Free", note: "After limit hit" },
  { name: "Claude Free", ctx: 30000, cat: "free", access: "Free", note: "Limited messages/day" },
  { name: "Gemini Free", ctx: 32000, cat: "free", access: "Free" },
  { name: "Copilot Free (Bing/Edge)", ctx: 8000, cat: "free", access: "Free", note: "Estimated" },
  { name: "Grok Free (X)", ctx: 32000, cat: "free", access: "Free with X account", note: "Estimated" },
  { name: "DeepSeek Chat (web)", ctx: 32000, cat: "free", access: "Free", note: "Limited daily use" },
  { name: "Mistral Le Chat Free", ctx: 32000, cat: "free", access: "Free" },
  { name: "HuggingChat Free", ctx: 8192, cat: "free", access: "Free", note: "Varies by model" },

  // PAID CONSUMER ($20/mo)
  { name: "ChatGPT Plus (Instant)", ctx: 32000, cat: "paid", access: "$20/mo" },
  { name: "ChatGPT Plus (Thinking)", ctx: 196000, cat: "paid", access: "$20/mo" },
  { name: "Claude Pro", ctx: 200000, cat: "paid", access: "$20/mo" },
  { name: "Gemini Advanced", ctx: 1000000, cat: "paid", access: "$20/mo" },
  { name: "Grok Premium (X Premium+)", ctx: 128000, cat: "paid", access: "$22/mo", note: "Estimated" },
  { name: "Copilot Pro", ctx: 128000, cat: "paid", access: "$20/mo", note: "Estimated" },
  { name: "Perplexity Pro", ctx: 32000, cat: "paid", access: "$20/mo", note: "Varies by query" },

  // PRO / BUSINESS ($25-200/mo)
  { name: "ChatGPT Business (Instant)", ctx: 32000, cat: "pro", access: "$25/user/mo" },
  { name: "ChatGPT Business (Thinking)", ctx: 196000, cat: "pro", access: "$25/user/mo" },
  { name: "ChatGPT Pro", ctx: 196000, cat: "pro", access: "$200/mo" },
  { name: "Claude Max (5x usage)", ctx: 200000, cat: "pro", access: "$100/mo" },
  { name: "Claude Team", ctx: 200000, cat: "pro", access: "$30/user/mo" },

  // ENTERPRISE
  { name: "ChatGPT Enterprise (GPT-5.1)", ctx: 128000, cat: "enterprise", access: "Enterprise pricing" },
  { name: "ChatGPT Enterprise (Thinking)", ctx: 196000, cat: "enterprise", access: "Enterprise pricing" },
  { name: "Claude Enterprise", ctx: 500000, cat: "enterprise", access: "Enterprise pricing" },
  { name: "Claude Sonnet 4.5 (1M beta)", ctx: 1000000, cat: "enterprise", access: "Tier 4+", note: "2x input pricing over 200K" },

  // API — PREMIUM
  { name: "Claude Opus 4.5 API", ctx: 200000, cat: "api-premium", access: "$15 / $75 per M tokens" },
  { name: "Claude Sonnet 4.5 API", ctx: 200000, cat: "api-premium", access: "$3 / $15 per M tokens", note: "1M beta available" },
  { name: "Claude Haiku 4.5 API", ctx: 200000, cat: "api-premium", access: "$0.80 / $4 per M tokens" },
  { name: "GPT-5.2 API", ctx: 400000, cat: "api-premium", access: "$1.50 / $6 per M tokens" },
  { name: "GPT-4.1 API", ctx: 1000000, cat: "api-premium", access: "$2 / $8 per M tokens" },
  { name: "GPT-4.1 Mini API", ctx: 1000000, cat: "api-premium", access: "$0.40 / $1.60 per M tokens" },
  { name: "Gemini 3 Pro API", ctx: 1000000, cat: "api-premium", access: "$12 per M tokens" },
  { name: "Gemini 2.5 Pro API", ctx: 1000000, cat: "api-premium", access: "$2.50 per M tokens" },
  { name: "Gemini 2.5 Flash API", ctx: 1000000, cat: "api-premium", access: "$0.15 per M tokens" },
  { name: "Grok 4.1 API", ctx: 2000000, cat: "api-premium", access: "$3 per M tokens" },

  // API — BUDGET / OPEN SOURCE
  { name: "DeepSeek V3 API", ctx: 128000, cat: "api-budget", access: "$0.27 per M tokens" },
  { name: "DeepSeek R1 API", ctx: 128000, cat: "api-budget", access: "$0.55 per M tokens" },
  { name: "Mistral Medium 3.1 API", ctx: 128000, cat: "api-budget", access: "$0.40 per M tokens" },
  { name: "Mistral Small 3 API", ctx: 32000, cat: "api-budget", access: "$0.10 per M tokens" },
  { name: "Qwen3 (hosted) API", ctx: 131072, cat: "api-budget", access: "Various providers" },
  { name: "Llama 3.1 8B (hosted)", ctx: 128000, cat: "api-budget", access: "Various · ~$0.05/M" },
  { name: "Llama 3.1 70B (hosted)", ctx: 128000, cat: "api-budget", access: "Various · ~$0.50/M" },
  { name: "Gemma 3 27B (hosted)", ctx: 128000, cat: "api-budget", access: "$0.07 per M tokens" },
  { name: "GPT-5.1 Mini API", ctx: 128000, cat: "api-budget", access: "$1.10 per M tokens" },

  // SELF-HOSTED API (max context, not typical)
  { name: "Llama 4 Scout (self-hosted)", ctx: 10000000, cat: "self-hosted-max", access: "Your infrastructure", note: "10M advertised, degrades after 128K" },
  { name: "Llama 4 Maverick (self-hosted)", ctx: 1000000, cat: "self-hosted-max", access: "Your infrastructure" },
  { name: "Llama 3.1 405B (self-hosted)", ctx: 128000, cat: "self-hosted-max", access: "Multi-GPU required" },
  { name: "Mistral Large 2 (self-hosted)", ctx: 128000, cat: "self-hosted-max", access: "Your infrastructure" },
  { name: "Qwen 2.5 72B (self-hosted)", ctx: 131072, cat: "self-hosted-max", access: "Your infrastructure" },
  { name: "DeepSeek R1 671B (self-hosted)", ctx: 128000, cat: "self-hosted-max", access: "Multi-GPU required" },
];

const CATEGORIES = [
  { id: "edge", label: "On-Device / Edge", color: "#ec4899" },
  { id: "local", label: "Local (Ollama / llama.cpp)", color: "#ef4444" },
  { id: "free", label: "Free Tiers", color: "#f97316" },
  { id: "paid", label: "Paid Consumer ($20/mo)", color: "#eab308" },
  { id: "pro", label: "Pro / Business ($25-200/mo)", color: "#22c55e" },
  { id: "enterprise", label: "Enterprise", color: "#3b82f6" },
  { id: "api-premium", label: "API — Premium", color: "#8b5cf6" },
  { id: "api-budget", label: "API — Budget & Open Source", color: "#06b6d4" },
  { id: "self-hosted-max", label: "Self-Hosted (Max Advertised)", color: "#64748b" },
];

const NOTATIONS = [
  { name: "FULL", tokens: 950, label: "Human + Machine readable" },
  { name: "COMPACT", tokens: 475, label: "Abbreviated, scannable" },
  { name: "TERSE", tokens: 200, label: "Telegraphic, machine-focused" },
];

const FIDELITIES = [
  { name: "MAX", mult: 1.0, label: "Everything preserved" },
  { name: "HIGH", mult: 0.75, label: "Drop energy/constraints" },
  { name: "LOW", mult: 0.37, label: "Core decisions + threads" },
  { name: "MIN", mult: 0.16, label: "Essence + handoff only" },
];

function getImpact(pct) {
  const t = T[state.lang] || T.en;
  const il = t.impact;
  if (pct >= 20) return { label: il.TRANSFORMATIVE, color: "#ef4444" };
  if (pct >= 10) return { label: il.CRITICAL, color: "#ef4444" };
  if (pct >= 5)  return { label: il.HIGH, color: "#f97316" };
  if (pct >= 2)  return { label: il.SIGNIFICANT, color: "#eab308" };
  if (pct >= 0.5) return { label: il.MODERATE, color: "#22c55e" };
  if (pct >= 0.1) return { label: il.LOW, color: "#3b82f6" };
  return { label: il.NEGLIGIBLE, color: "#64748b" };
}

function fmtPct(p) {
  if (p >= 10) return p.toFixed(1) + "%";
  if (p >= 1) return p.toFixed(1) + "%";
  if (p >= 0.1) return p.toFixed(2) + "%";
  if (p >= 0.01) return p.toFixed(3) + "%";
  return "<0.01%";
}

function fmtTokens(t) {
  if (t >= 1000000) return (t/1000000).toFixed(t >= 10000000 ? 0 : 0) + "M";
  if (t >= 1000) return (t/1000).toFixed(0) + "K";
  return t.toString();
}

// State
let state = {
  notation: 0,
  fidelity: 0,
  visibleCats: new Set(CATEGORIES.map(c => c.id)),
  lang: detectLang(),
  cardModels: [null, null, null, null], // explicit model names per card slot, null = auto
};

function getTokens() {
  return Math.round(NOTATIONS[state.notation].tokens * FIDELITIES[state.fidelity].mult);
}

// Pick 4 models for comparison cards
// Respects explicit user selections per slot, fills empty slots with spread picks
function pickCompareModels(forceShuffle) {
  const pool = MODELS.filter(m => state.visibleCats.has(m.cat));
  if (pool.length === 0) return [];

  const result = [null, null, null, null];
  const usedNames = new Set();

  // First pass: honor explicit user picks that are still in the visible pool
  state.cardModels.forEach((name, i) => {
    if (name) {
      const m = pool.find(m => m.name === name);
      if (m) { result[i] = m; usedNames.add(m.name); }
      else { state.cardModels[i] = null; } // model no longer visible, clear it
    }
  });

  // Second pass: fill empty slots
  const emptySlots = result.map((m, i) => m ? -1 : i).filter(i => i >= 0);
  if (emptySlots.length > 0) {
    const available = pool.filter(m => !usedNames.has(m.name));

    if (forceShuffle || available.length <= emptySlots.length) {
      // Random fill
      const shuffled = [...available].sort(() => Math.random() - 0.5);
      emptySlots.forEach((slot, j) => {
        if (j < shuffled.length) {
          result[slot] = shuffled[j];
          state.cardModels[slot] = shuffled[j].name;
        }
      });
    } else {
      // Spread: pick from different context sizes for visual contrast
      available.sort((a, b) => a.ctx - b.ctx);
      const step = Math.max(1, Math.floor(available.length / emptySlots.length));
      emptySlots.forEach((slot, j) => {
        const idx = Math.min(j * step, available.length - 1);
        const pick = available[idx];
        if (pick && !usedNames.has(pick.name)) {
          result[slot] = pick;
          usedNames.add(pick.name);
          state.cardModels[slot] = pick.name;
        }
      });
    }
  }

  return result.filter(Boolean);
}

function render() {
  const t = T[state.lang] || T.en;
  const dir = t.dir || 'ltr';
  document.documentElement.setAttribute('dir', dir);
  document.documentElement.setAttribute('lang', state.lang);

  const tokens = getTokens();
  function barScale(pct) {
    return Math.max(0.3, Math.min(100, pct));
  }

  const n = NOTATIONS[state.notation];
  const f = FIDELITIES[state.fidelity];

  let html = '';

  // --- Language selector ---
  html += `<div class="lang-bar">
    <label>🌐</label>
    <select class="lang-select" onchange="setLang(this.value)">`;
  Object.keys(T).forEach(code => {
    html += `<option value="${code}" ${state.lang === code ? 'selected' : ''}>${T[code].lang}</option>`;
  });
  html += `</select>
    <span class="lang-pop">22 languages · ~95% of internet users</span>
  </div>`;

  // --- Header ---
  html += `
    <div class="header">
      <div class="header-tag">${t.tag.replace('CC BY-SA 4.0', '<span class="license-link" onclick="openLicense()">CC BY-SA 4.0</span>')}</div>
      <h1>${t.title}</h1>
      <p>${t.subtitle}
      <br><span class="highlight">${t.highlight}</span></p>
      <div class="universal">${t.universal}</div>
    </div>
  `;

  // --- Controls ---
  html += `<div class="controls">`;
  html += `<div class="control-group"><label>${t.notation}</label><div class="btn-row">`;
  NOTATIONS.forEach((nt, i) => {
    html += `<button class="btn ${state.notation === i ? 'active' : ''}" onclick="setNotation(${i})">${nt.name}</button>`;
  });
  html += `</div></div>`;

  html += `<div class="control-group"><label>${t.fidelity}</label><div class="btn-row">`;
  FIDELITIES.forEach((fi, i) => {
    html += `<button class="btn ${state.fidelity === i ? 'active' : ''}" onclick="setFidelity(${i})">${fi.name}</button>`;
  });
  html += `</div></div>`;
  html += `</div>`;

  // --- Token Display ---
  const fidLabel = t.fidLabels[state.fidelity] || f.label;
  const notLabel = t.notLabels[state.notation] || n.label;
  html += `
    <div class="token-display">
      <span class="num">${tokens}</span>
      <span class="meta">${t.tokens} · ${notLabel} · ${fidLabel} · <span style="color:var(--accent-cyan)">${t.anyModel}</span></span>
    </div>
  `;

  // --- Quick Compare Cards (dropdown picker per card) ---
  const picks = pickCompareModels();
  const pool = MODELS.filter(m => state.visibleCats.has(m.cat)).sort((a,b) => a.ctx - b.ctx);

  html += `<div class="quick-compare-header">
    <button class="shuffle-btn" onclick="shuffleCards()" title="Randomize">&#x21bb; shuffle</button>
  </div>`;
  html += `<div class="quick-compare">`;
  picks.forEach((m, i) => {
    const pct = (tokens / m.ctx) * 100;
    html += `<div class="compare-card">
      <div class="label-row">
        <select class="model-pick" onchange="setCardModel(${i}, this.value)">`;
    pool.forEach(pm => {
      html += `<option value="${pm.name}" ${pm.name === m.name ? 'selected' : ''}>${pm.name} (${fmtTokens(pm.ctx)})</option>`;
    });
    html += `</select>
      </div>
      <div class="value" style="color:${getImpact(pct).color}">${fmtPct(pct)}</div>
      <div class="sub">${t.ofContext}</div>
    </div>`;
  });
  html += `</div>`;

  // --- Category Filters ---
  const catLabels = t.catLabels || {};
  html += `<div style="margin-top:28px"><div class="control-group"><label>${t.showCats}</label></div></div>`;
  html += `<div class="filter-bar">`;
  html += `<button class="filter-btn ${state.visibleCats.size === CATEGORIES.length ? 'active' : ''}" onclick="toggleAll()">${t.all}</button>`;
  CATEGORIES.forEach(c => {
    const label = catLabels[c.id] || c.label;
    html += `<button class="filter-btn ${state.visibleCats.has(c.id) ? 'active' : ''}"
      style="${state.visibleCats.has(c.id) ? 'border-color:'+c.color+';color:'+c.color : ''}"
      onclick="toggleCat('${c.id}')">${label}</button>`;
  });
  html += `</div>`;

  // --- Model Rows ---
  CATEGORIES.forEach(cat => {
    if (!state.visibleCats.has(cat.id)) return;
    const catModels = MODELS.filter(m => m.cat === cat.id);
    if (catModels.length === 0) return;
    const catLabel = catLabels[cat.id] || cat.label;

    html += `<div class="category">`;
    html += `<div class="category-header" style="border-color:${cat.color}40">${catLabel} <span style="color:${cat.color}">·</span> ${catModels.length} ${t.models}</div>`;

    catModels.forEach(m => {
      const pct = (tokens / m.ctx) * 100;
      const impact = getImpact(pct);
      const barW = barScale(pct);

      html += `<div class="model-row">
        <div class="model-name">${m.name}${m.note ? `<span class="access" title="${m.note}"> ⓘ</span>` : ''}</div>
        <div class="model-ctx">${fmtTokens(m.ctx)}</div>
        <div class="bar-container"><div class="bar-fill" style="width:${barW}%;background:${impact.color}"></div></div>
        <div class="model-pct" style="color:${impact.color}">${fmtPct(pct)}</div>
        <div class="model-impact" style="color:${impact.color}">${impact.label}</div>
      </div>`;
    });

    html += `</div>`;
  });

  // --- Insight Box (dynamic based on picked models) ---
  const smallest = picks[0];
  const largest = picks[picks.length - 1];
  const smallPct = smallest ? (tokens / smallest.ctx) * 100 : 0;
  const largePct = largest ? (tokens / largest.ctx) * 100 : 0;

  // Dynamic insight text
  let insightText = '';
  if (picks.length >= 2) {
    insightText = `${t.insight(tokens, fmtPct(smallPct), 
      picks.length >= 3 ? fmtPct((tokens / picks[Math.floor(picks.length/2)].ctx) * 100) : fmtPct(largePct),
      fmtPct(largePct))}`;
  }

  html += `<div class="insight">
    <div class="insight-label">${t.insightLabel}</div>
    <div class="insight-body">
      ${insightText}
      <br><br>
      <span class="red">${t.insightPunch}</span>
      <br><br>
      ${tokens <= 200
        ? t.terseTip(tokens, fmtPct(smallPct))
        : tokens <= 500
        ? t.compactTip
        : t.fullTip
      }
    </div>
  </div>`;

  // --- Footer (English only — sources are English URLs) ---
  html += `<div class="footer">
    <strong>Sources:</strong> ChatGPT context limits from
    <a href="https://help.openai.com/en/articles/11909943-gpt-5-in-chatgpt" target="_blank">OpenAI Help Center</a> (Feb 2026).
    Claude from <a href="https://docs.anthropic.com" target="_blank">Anthropic docs</a>.
    Local model defaults from <a href="https://docs.ollama.com/context-length" target="_blank">Ollama docs</a>.
    Gemini, Grok, Llama, Mistral, DeepSeek from official documentation and
    <a href="https://artificialanalysis.ai/leaderboards/models" target="_blank">Artificial Analysis</a>.
    Free tier / paid estimates where official numbers not published.
    AIST token counts based on v0.5 MAX handoff measurements (~950 tokens at FULL notation).
    <br><br>
    <a href="https://github.com/robiw/aist-protocol" target="_blank">AIST Protocol on GitHub</a> · <span class="license-link" onclick="openLicense()">CC BY-SA 4.0</span>
  </div>`;

  document.getElementById('app').innerHTML = html;
}

// Event handlers
function setNotation(i) { state.notation = i; render(); }
function setFidelity(i) { state.fidelity = i; render(); }
function setLang(code) { state.lang = code; render(); }
function setCardModel(slot, name) { state.cardModels[slot] = name; render(); }
function shuffleCards() { state.cardModels = [null, null, null, null]; pickCompareModels(true); render(); }
function openLicense() { document.getElementById('licenseModal').classList.add('open'); }
function closeLicense() { document.getElementById('licenseModal').classList.remove('open'); }
function toggleCat(id) {
  if (state.visibleCats.has(id)) state.visibleCats.delete(id);
  else state.visibleCats.add(id);
  render();
}
function toggleAll() {
  if (state.visibleCats.size === CATEGORIES.length) {
    state.visibleCats = new Set(["local", "free"]);
  } else {
    state.visibleCats = new Set(CATEGORIES.map(c => c.id));
  }
  render();
}

// Initial render
document.addEventListener('keydown', e => { if (e.key === 'Escape') closeLicense(); });
render();
</script>
</body>
</html>
